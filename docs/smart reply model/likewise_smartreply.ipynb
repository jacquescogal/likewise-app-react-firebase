{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('s2s.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 100)    1227200     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    748500      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 512),        1255424     ['embedding[0][0]']              \n",
      "                                 (None, 512),                                                     \n",
      "                                 (None, 512)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 512),  1255424     ['embedding_1[0][0]',            \n",
      "                                 (None, 512),                     'lstm[0][1]',                   \n",
      "                                 (None, 512)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 7485)   3839805     ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,326,353\n",
      "Trainable params: 8,326,353\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "encoder_model = load_model(\"encoder_model.hdf5\")\n",
    "decoder_model = load_model(\"decoder_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 100)         1227200   \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 512),             1255424   \n",
      "                              (None, 512),                       \n",
      "                              (None, 512)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,482,624\n",
      "Trainable params: 2,482,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    748500      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 512),  1255424     ['embedding_1[0][0]',            \n",
      "                                 (None, None),                    'input_3[0][0]',                \n",
      "                                 (None, None)]                    'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 7485)   3839805     ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,843,729\n",
      "Trainable params: 5,843,729\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_token_index.pickle', 'rb') as handle:\n",
    "    input_token_index = pickle.load(handle)\n",
    "    \n",
    "with open('target_token_index.pickle', 'rb') as handle:\n",
    "    target_token_index = pickle.load(handle)\n",
    "    \n",
    "# Reverse-lookup token index to decode sequences back \n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = 29\n",
    "\n",
    "def respond(text):\n",
    "    input_seq = np.zeros(\n",
    "        (1, max_encoder_seq_length), dtype=\"float32\"\n",
    "    )\n",
    "    \n",
    "    for t, word in enumerate(text.split()):\n",
    "        input_seq[0, t] = input_token_index[word]\n",
    "        \n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['bos']\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        \n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == 'eos' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_char\n",
    "            \n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' i do like the nba'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "eos_token = target_token_index['eos']\n",
    "\n",
    "\n",
    "# basic preprocessing\n",
    "def process(text):\n",
    "    text = text.lower().replace('\\n', ' ').replace('-', ' ').replace(':', ' ').replace(',', '') \\\n",
    "          .replace('\"', ' ').replace(\".\", \" \").replace(\"!\", \" \").replace(\"?\", \" \").replace(\";\", \" \").replace(\":\", \" \")\n",
    "\n",
    "    text = \"\".join(v for v in text if v not in string.punctuation).lower()\n",
    "    #text = text.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "\n",
    "    text = \" \".join(text.split())\n",
    "    #text+=\"<eos>\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "def generate_beam_text(seed_text, next_words, beam_search_n, break_at_eos):\n",
    "    \n",
    "    distributions_scores_states = [[list(), 0.0, [None, None]]]\n",
    "    \n",
    "    decoder_states_value = None\n",
    "    \n",
    "    answers = []\n",
    "    \n",
    "    for _ in range(next_words):\n",
    "        \n",
    "        sequence_temp_candidates = list()\n",
    "        \n",
    "        for i in range(len(distributions_scores_states)): \n",
    "            \n",
    "            input_seq = np.zeros(\n",
    "                (1, max_encoder_seq_length), dtype=\"float32\"\n",
    "            )\n",
    "            \n",
    "            # Generate empty target sequence of length 1.\n",
    "            target_seq = np.zeros((1,1))\n",
    "            \n",
    "            seq, score, states_values = distributions_scores_states[i]\n",
    "            \n",
    "            if len(distributions_scores_states) == 1:\n",
    "                for t, word in enumerate(process(seed_text).split()):\n",
    "                    input_seq[0, t] = input_token_index[word]\n",
    "                \n",
    "                # Encode the input as state vectors.\n",
    "                decoder_states_value = encoder_model.predict(input_seq)\n",
    "                \n",
    "                # Populate the first character of target sequence with the start character.\n",
    "                target_seq[0, 0] = target_token_index['bos']\n",
    "                \n",
    "            else:\n",
    "                target_seq[0, 0] = seq[-1]\n",
    "                decoder_states_value = states_values\n",
    "                \n",
    "                candidate_sentence = \"\"\n",
    "                for token_index in seq:\n",
    "                    if token_index == eos_token:\n",
    "                        break\n",
    "                        \n",
    "                    word = reverse_target_char_index[token_index]\n",
    "                    candidate_sentence+=word + \" \"\n",
    "                \n",
    "                #print(\"score :\", score, \" | \", candidate_sentence)\n",
    "                answers.append((score, candidate_sentence))\n",
    "            \n",
    "            \n",
    "            output_tokens_distribution, h, c = decoder_model.predict([target_seq] + decoder_states_value)\n",
    "            \n",
    "            # Update states\n",
    "            decoder_states_value = [h, c]\n",
    "\n",
    "            predicted_distribution = output_tokens_distribution[0][0]\n",
    "            \n",
    "            for j in range(len(predicted_distribution)):\n",
    "                if predicted_distribution[j] > 0:\n",
    "                    candidate = [seq + [j], score - log(predicted_distribution[j]), decoder_states_value]\n",
    "                    if break_at_eos and j == eos_token:\n",
    "                        continue\n",
    "                    else:\n",
    "                        sequence_temp_candidates.append(candidate)\n",
    "\n",
    "        \n",
    "        # 2. score and sort all candidates\n",
    "        ordered = sorted(sequence_temp_candidates, key=lambda tup:tup[1])\n",
    "        \n",
    "        distributions_scores_states = ordered[:beam_search_n]\n",
    "          \n",
    "        #print(\"-----\")\n",
    "    \n",
    "    final_return_list = [x[1] for x in sorted(answers, reverse = True)[:5]]\n",
    "    return(final_return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['yes i do like ', 'i do like the ', 'yes i do do ', 'i do i love ', 'i do i ']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_beam_text(\"hi do you like to dance\", 5, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
