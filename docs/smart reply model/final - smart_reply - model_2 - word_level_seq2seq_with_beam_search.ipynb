{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 5.677042,
     "end_time": "2021-03-27T10:27:41.122471",
     "exception": false,
     "start_time": "2021-03-27T10:27:35.445429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import string, os \n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.039265,
     "end_time": "2021-03-27T10:27:41.182809",
     "exception": false,
     "start_time": "2021-03-27T10:27:41.143544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n",
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.030066,
     "end_time": "2021-03-27T10:27:41.233999",
     "exception": false,
     "start_time": "2021-03-27T10:27:41.203933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 200  # Number of epochs to train for.\n",
    "latent_dim = 512  # Latent dimensionality of the encoding space.\n",
    "num_samples = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.826325,
     "end_time": "2021-03-27T10:27:42.080285",
     "exception": false,
     "start_time": "2021-03-27T10:27:41.253960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Are you a fan of Google or Microsoft?</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Both are excellent technology they are helpfu...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm not  a huge fan of Google, but I use it a...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Google provides online related services and p...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yeah, their services are good. I'm just not a...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id                                            message  \\\n",
       "0                1              Are you a fan of Google or Microsoft?   \n",
       "1                1   Both are excellent technology they are helpfu...   \n",
       "2                1   I'm not  a huge fan of Google, but I use it a...   \n",
       "3                1   Google provides online related services and p...   \n",
       "4                1   Yeah, their services are good. I'm just not a...   \n",
       "\n",
       "                 sentiment  \n",
       "0   Curious to dive deeper  \n",
       "1   Curious to dive deeper  \n",
       "2   Curious to dive deeper  \n",
       "3   Curious to dive deeper  \n",
       "4   Curious to dive deeper  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading dataset\n",
    "df = pd.read_csv('topical_chat.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.032472,
     "end_time": "2021-03-27T10:27:42.133454",
     "exception": false,
     "start_time": "2021-03-27T10:27:42.100982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basic preprocessing\n",
    "def process(text):\n",
    "    text = text.lower().replace('\\n', ' ').replace('-', ' ').replace(':', ' ').replace(',', '') \\\n",
    "          .replace('\"', ' ').replace(\".\", \" \").replace(\"!\", \" \").replace(\"?\", \" \").replace(\";\", \" \").replace(\":\", \" \")\n",
    "\n",
    "    text = \"\".join(v for v in text if v not in string.punctuation).lower()\n",
    "    #text = text.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "\n",
    "    text = \" \".join(text.split())\n",
    "    #text+=\"<eos>\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 3.951903,
     "end_time": "2021-03-27T10:27:46.107320",
     "exception": false,
     "start_time": "2021-03-27T10:27:42.155417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.message = df.message.apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.036619,
     "end_time": "2021-03-27T10:27:46.165567",
     "exception": false,
     "start_time": "2021-03-27T10:27:46.128948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>are you a fan of google or microsoft</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>both are excellent technology they are helpful...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>im not a huge fan of google but i use it a lot...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>google provides online related services and pr...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>yeah their services are good im just not a fan...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id                                            message  \\\n",
       "0                1               are you a fan of google or microsoft   \n",
       "1                1  both are excellent technology they are helpful...   \n",
       "2                1  im not a huge fan of google but i use it a lot...   \n",
       "3                1  google provides online related services and pr...   \n",
       "4                1  yeah their services are good im just not a fan...   \n",
       "\n",
       "                 sentiment  \n",
       "0   Curious to dive deeper  \n",
       "1   Curious to dive deeper  \n",
       "2   Curious to dive deeper  \n",
       "3   Curious to dive deeper  \n",
       "4   Curious to dive deeper  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 83.988346,
     "end_time": "2021-03-27T10:29:10.174583",
     "exception": false,
     "start_time": "2021-03-27T10:27:46.186237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 188378/188378 [02:40<00:00, 1174.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_words_set = set()\n",
    "target_words_set = set()\n",
    "\n",
    "for conversation_index in tqdm(range(df.shape[0])):\n",
    "    \n",
    "    if conversation_index == 0:\n",
    "        continue\n",
    "        \n",
    "    input_text = df.iloc[conversation_index - 1]\n",
    "    target_text = df.iloc[conversation_index]\n",
    "    \n",
    "    if input_text.conversation_id == target_text.conversation_id:\n",
    "        \n",
    "        input_text = input_text.message\n",
    "        target_text = target_text.message\n",
    "        \n",
    "        if len(input_text.split()) > 2 and \\\n",
    "            len(target_text.split()) > 0 and \\\n",
    "            len(input_text.split()) < 30 and \\\n",
    "            len(target_text.split()) < 10 and \\\n",
    "            input_text and \\\n",
    "            target_text:\n",
    "            \n",
    "            target_text = \"bos \" + target_text + \" eos\"\n",
    "                \n",
    "            input_texts.append(input_text)\n",
    "            target_texts.append(target_text)\n",
    "            \n",
    "            for word in input_text.split():\n",
    "                if word not in input_words_set:\n",
    "                    input_words_set.add(word)\n",
    "            for word in target_text.split():\n",
    "                if word not in target_words_set:\n",
    "                    target_words_set.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 1.185284,
     "end_time": "2021-03-27T10:29:11.650408",
     "exception": false,
     "start_time": "2021-03-27T10:29:10.465124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 20190\n",
      "Number of unique input tokens: 12272\n",
      "Number of unique output tokens: 7485\n",
      "Max sequence length for inputs: 29\n",
      "Max sequence length for outputs: 11\n"
     ]
    }
   ],
   "source": [
    "input_words = sorted(list(input_words_set))\n",
    "target_words = sorted(list(target_words_set))\n",
    "num_encoder_tokens = len(input_words)\n",
    "num_decoder_tokens = len(target_words)\n",
    "max_encoder_seq_length = max([len(txt.split()) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt.split()) for txt in target_texts])\n",
    "\n",
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict([(word, i) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i) for i, word in enumerate(target_words)])\n",
    "\n",
    "#saving\n",
    "with open('input_token_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(input_token_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#saving\n",
    "with open('target_token_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(target_token_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    \n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data[i, t] = input_token_index[word]\n",
    "    \n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = target_token_index[word]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[word]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 4.739496,
     "end_time": "2021-03-27T10:29:16.676042",
     "exception": false,
     "start_time": "2021-03-27T10:29:11.936546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 100)    1227200     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    748500      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 512),        1255424     ['embedding[0][0]']              \n",
      "                                 (None, 512),                                                     \n",
      "                                 (None, 512)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 512),  1255424     ['embedding_1[0][0]',            \n",
      "                                 (None, 512),                     'lstm[0][1]',                   \n",
      "                                 (None, 512)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 7485)   3839805     ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,326,353\n",
      "Trainable params: 8,326,353\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 100\n",
    "\n",
    "# seq2seq model - https://keras.io/examples/nlp/lstm_seq2seq/\n",
    "with strategy.scope():\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = keras.Input(shape=(None,))\n",
    "    \n",
    "    encoder_embedding_output = keras.layers.Embedding(num_encoder_tokens, embedding_size)(encoder_inputs)\n",
    "                                               \n",
    "    encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_embedding_output)\n",
    "\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = keras.Input(shape=(None,))\n",
    "    \n",
    "    decoder_embedding = keras.layers.Embedding(num_decoder_tokens, embedding_size)\n",
    "    decoder_embedding_output = decoder_embedding(decoder_inputs)\n",
    "    \n",
    "\n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the\n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding_output, initial_state=encoder_states)\n",
    "    decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 407.246187,
     "end_time": "2021-03-27T10:36:04.207870",
     "exception": false,
     "start_time": "2021-03-27T10:29:16.961683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "284/284 [==============================] - 240s 817ms/step - loss: 3.9531 - accuracy: 0.1128 - val_loss: 3.8866 - val_accuracy: 0.1160\n",
      "Epoch 2/20\n",
      "284/284 [==============================] - 226s 795ms/step - loss: 3.7194 - accuracy: 0.1253 - val_loss: 3.7856 - val_accuracy: 0.1310\n",
      "Epoch 3/20\n",
      "284/284 [==============================] - 226s 795ms/step - loss: 3.5949 - accuracy: 0.1364 - val_loss: 3.6734 - val_accuracy: 0.1449\n",
      "Epoch 4/20\n",
      "284/284 [==============================] - 224s 789ms/step - loss: 3.4604 - accuracy: 0.1543 - val_loss: 3.5760 - val_accuracy: 0.1582\n",
      "Epoch 5/20\n",
      "284/284 [==============================] - 226s 796ms/step - loss: 3.3397 - accuracy: 0.1686 - val_loss: 3.4917 - val_accuracy: 0.1694\n",
      "Epoch 6/20\n",
      "284/284 [==============================] - 227s 798ms/step - loss: 3.2224 - accuracy: 0.1795 - val_loss: 3.4060 - val_accuracy: 0.1816\n",
      "Epoch 7/20\n",
      "284/284 [==============================] - 227s 798ms/step - loss: 3.1146 - accuracy: 0.1878 - val_loss: 3.3315 - val_accuracy: 0.1853\n",
      "Epoch 8/20\n",
      "284/284 [==============================] - 222s 782ms/step - loss: 3.0147 - accuracy: 0.1946 - val_loss: 3.2846 - val_accuracy: 0.1930\n",
      "Epoch 9/20\n",
      "284/284 [==============================] - 227s 799ms/step - loss: 2.9189 - accuracy: 0.2028 - val_loss: 3.2405 - val_accuracy: 0.1978\n",
      "Epoch 10/20\n",
      "284/284 [==============================] - 200s 705ms/step - loss: 2.8246 - accuracy: 0.2118 - val_loss: 3.2065 - val_accuracy: 0.2021\n",
      "Epoch 11/20\n",
      "284/284 [==============================] - 222s 781ms/step - loss: 2.7360 - accuracy: 0.2192 - val_loss: 3.1898 - val_accuracy: 0.2040\n",
      "Epoch 12/20\n",
      "284/284 [==============================] - 240s 846ms/step - loss: 2.6519 - accuracy: 0.2255 - val_loss: 3.1688 - val_accuracy: 0.2082\n",
      "Epoch 13/20\n",
      "284/284 [==============================] - 220s 775ms/step - loss: 2.5693 - accuracy: 0.2324 - val_loss: 3.1818 - val_accuracy: 0.2116\n",
      "Epoch 14/20\n",
      "284/284 [==============================] - 191s 671ms/step - loss: 2.4919 - accuracy: 0.2389 - val_loss: 3.2239 - val_accuracy: 0.2144\n",
      "Epoch 15/20\n",
      "284/284 [==============================] - 190s 668ms/step - loss: 2.4186 - accuracy: 0.2444 - val_loss: 3.2636 - val_accuracy: 0.2178\n",
      "Epoch 16/20\n",
      "284/284 [==============================] - 185s 651ms/step - loss: 2.3478 - accuracy: 0.2518 - val_loss: 3.3030 - val_accuracy: 0.2188\n",
      "Epoch 17/20\n",
      "284/284 [==============================] - 185s 653ms/step - loss: 2.2801 - accuracy: 0.2577 - val_loss: 3.3722 - val_accuracy: 0.2188\n",
      "Epoch 18/20\n",
      "284/284 [==============================] - 198s 698ms/step - loss: 2.2180 - accuracy: 0.2647 - val_loss: 3.4558 - val_accuracy: 0.2166\n",
      "Epoch 19/20\n",
      "284/284 [==============================] - 194s 683ms/step - loss: 2.1570 - accuracy: 0.2710 - val_loss: 3.5352 - val_accuracy: 0.2212\n",
      "Epoch 20/20\n",
      "284/284 [==============================] - 203s 716ms/step - loss: 2.1004 - accuracy: 0.2776 - val_loss: 3.6157 - val_accuracy: 0.2190\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=20,\n",
    "    validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e30ec20c70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 2.418151,
     "end_time": "2021-03-27T10:36:09.054857",
     "exception": false,
     "start_time": "2021-03-27T10:36:06.636706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 2.352986,
     "end_time": "2021-03-27T10:36:13.528407",
     "exception": false,
     "start_time": "2021-03-27T10:36:11.175421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(\"s2s.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 2.82737,
     "end_time": "2021-03-27T10:36:18.494887",
     "exception": false,
     "start_time": "2021-03-27T10:36:15.667517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 100)         1227200   \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 512),             1255424   \n",
      "                              (None, 512),                       \n",
      "                              (None, 512)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,482,624\n",
      "Trainable params: 2,482,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the encoder model \n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "encoder_model.summary()\n",
    "\n",
    "decoder_state_input_h = keras.Input(shape=(None,))\n",
    "decoder_state_input_c = keras.Input(shape=(None,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_embedding_output = decoder_embedding(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_embedding_output, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "# Reverse-lookup token index to decode sequences back \n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 2.185785,
     "end_time": "2021-03-27T10:36:22.874747",
     "exception": false,
     "start_time": "2021-03-27T10:36:20.688962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "encoder_model.save(\"encoder_model.hdf5\")\n",
    "decoder_model.save(\"decoder_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_encoder_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 2.167144,
     "end_time": "2021-03-27T10:36:27.149927",
     "exception": false,
     "start_time": "2021-03-27T10:36:24.982783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def respond(text):\n",
    "    input_seq = np.zeros(\n",
    "        (1, max_encoder_seq_length), dtype=\"float32\"\n",
    "    )\n",
    "    \n",
    "    for t, word in enumerate(text.split()):\n",
    "        input_seq[0, t] = input_token_index[word]\n",
    "        \n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['bos']\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        \n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == 'eos' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_char\n",
    "            \n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "papermill": {
     "duration": 3.208566,
     "end_time": "2021-03-27T10:36:32.849696",
     "exception": false,
     "start_time": "2021-03-27T10:36:29.641130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' i am doing well how are you'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 2.604019,
     "end_time": "2021-03-27T10:36:38.207095",
     "exception": false,
     "start_time": "2021-03-27T10:36:35.603076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' i have not heard of the movie'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"good morning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "papermill": {
     "duration": 2.259753,
     "end_time": "2021-03-27T10:36:42.948406",
     "exception": false,
     "start_time": "2021-03-27T10:36:40.688653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' you too'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"good bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "papermill": {
     "duration": 10.895664,
     "end_time": "2021-03-27T10:36:55.985527",
     "exception": false,
     "start_time": "2021-03-27T10:36:45.089863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "-\n",
      "Input sentence: yes google is the biggest search engine and google service figure out top 100 website including youtube and blogger\n",
      "Decoded sentence:  that is true do you like to travel\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "-\n",
      "Input sentence: yes he even won a hardcore cha cha championship in 1958\n",
      "Decoded sentence:  yeah do you know who kareem abdul jabbar is\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "-\n",
      "Input sentence: true did you know jackson had a patent on a dancing device\n",
      "Decoded sentence:  yes and he has already released 3 albums\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "-\n",
      "Input sentence: yes it helped him smooth out his dance moves\n",
      "Decoded sentence:  do you like the internet\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "-\n",
      "Input sentence: i wonder if they met how that would go from there\n",
      "Decoded sentence:  yeah it was nice chatting with you\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "-\n",
      "Input sentence: oh yeah i didnt know that either i also want to go to google plex to see the goats who mow their lawn by eating it\n",
      "Decoded sentence:  thats true i wonder why it was\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "-\n",
      "Input sentence: hi do you like to dance\n",
      "Decoded sentence:  i do like to watch the simpsons\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "-\n",
      "Input sentence: dancing is a lot of fun did you know that bruce lee was a great dancer\n",
      "Decoded sentence:  i did not know that is pretty cool\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "-\n",
      "Input sentence: he was indeed his music is even in the library of congress\n",
      "Decoded sentence:  i wonder how many listeners he was it\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "-\n",
      "Input sentence: wow that is amazing coming from such a talented singer and dancer i couldnt even dance like that even if i dreamed of it\n",
      "Decoded sentence:  i wonder if they are kicking themselves to the same\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "-\n",
      "Input sentence: i heard that some professional ballet dancer can go through four pairs of shoes in a week\n",
      "Decoded sentence:  that is true do you like to travel\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "-\n",
      "Input sentence: ha ha it was so nice chatting with you as well have a nice day bye\n",
      "Decoded sentence:  you too\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "-\n",
      "Input sentence: yes he was in the nutcracker as the mouse king\n",
      "Decoded sentence:  yes and he was released president banana\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "-\n",
      "Input sentence: i wonder if they had met what he would have written about her\n",
      "Decoded sentence:  yeah do you like to read\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "-\n",
      "Input sentence: yeah good point he also invented some womens names\n",
      "Decoded sentence:  yes and they scheduled 2430 energetically\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "-\n",
      "Input sentence: and before on google moon they used to use cheese for close ups\n",
      "Decoded sentence:  i wonder if they are kicking themselves to\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "-\n",
      "Input sentence: do you know how google maps calculates traffic\n",
      "Decoded sentence:  i love to travel how about you\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "-\n",
      "Input sentence: i am not sure how do they do this\n",
      "Decoded sentence:  i do like to watch the simpsons\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "-\n",
      "Input sentence: but i like that they like to have fun too have you ever typed askew into google\n",
      "Decoded sentence:  i have not heard of the most of the movie\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "-\n",
      "Input sentence: do you like comic books\n",
      "Decoded sentence:  i do like to watch the simpsons\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(20):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    decoded_sentence = respond(input_texts[seq_index])\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "papermill": {
     "duration": 2.141757,
     "end_time": "2021-03-27T10:37:00.330656",
     "exception": false,
     "start_time": "2021-03-27T10:36:58.188899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2367"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_token = target_token_index['eos']\n",
    "eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "papermill": {
     "duration": 2.119635,
     "end_time": "2021-03-27T10:37:04.842590",
     "exception": false,
     "start_time": "2021-03-27T10:37:02.722955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "def generate_beam_text(seed_text, next_words, beam_search_n, break_at_eos):\n",
    "    \n",
    "    distributions_scores_states = [[list(), 0.0, [None, None]]]\n",
    "    \n",
    "    decoder_states_value = None\n",
    "    \n",
    "    for _ in range(next_words):\n",
    "        \n",
    "        sequence_temp_candidates = list()\n",
    "        \n",
    "        for i in range(len(distributions_scores_states)): \n",
    "            \n",
    "            input_seq = np.zeros(\n",
    "                (1, max_encoder_seq_length), dtype=\"float32\"\n",
    "            )\n",
    "            \n",
    "            # Generate empty target sequence of length 1.\n",
    "            target_seq = np.zeros((1,1))\n",
    "            \n",
    "            seq, score, states_values = distributions_scores_states[i]\n",
    "            \n",
    "            if len(distributions_scores_states) == 1:\n",
    "                for t, word in enumerate(process(seed_text).split()):\n",
    "                    input_seq[0, t] = input_token_index[word]\n",
    "                \n",
    "                # Encode the input as state vectors.\n",
    "                decoder_states_value = encoder_model.predict(input_seq)\n",
    "                \n",
    "                # Populate the first character of target sequence with the start character.\n",
    "                target_seq[0, 0] = target_token_index['bos']\n",
    "                \n",
    "            else:\n",
    "                target_seq[0, 0] = seq[-1]\n",
    "                decoder_states_value = states_values\n",
    "                \n",
    "                candidate_sentence = \"\"\n",
    "                for token_index in seq:\n",
    "                    if token_index == eos_token:\n",
    "                        break\n",
    "                        \n",
    "                    word = reverse_target_char_index[token_index]\n",
    "                    candidate_sentence+=word + \" \"\n",
    "                \n",
    "                print(\"score :\", score, \" | \", candidate_sentence)\n",
    "            \n",
    "            \n",
    "            output_tokens_distribution, h, c = decoder_model.predict([target_seq] + decoder_states_value)\n",
    "            \n",
    "            # Update states\n",
    "            decoder_states_value = [h, c]\n",
    "\n",
    "            predicted_distribution = output_tokens_distribution[0][0]\n",
    "            \n",
    "            for j in range(len(predicted_distribution)):\n",
    "                if predicted_distribution[j] > 0:\n",
    "                    candidate = [seq + [j], score - log(predicted_distribution[j]), decoder_states_value]\n",
    "                    if break_at_eos and j == eos_token:\n",
    "                        continue\n",
    "                    else:\n",
    "                        sequence_temp_candidates.append(candidate)\n",
    "\n",
    "        \n",
    "        # 2. score and sort all candidates\n",
    "        ordered = sorted(sequence_temp_candidates, key=lambda tup:tup[1])\n",
    "        \n",
    "        distributions_scores_states = ordered[:beam_search_n]\n",
    "          \n",
    "        print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "papermill": {
     "duration": 5.390994,
     "end_time": "2021-03-27T10:37:12.848152",
     "exception": false,
     "start_time": "2021-03-27T10:37:07.457158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "-----\n",
      "score : 2.419793438682456  |  yeah \n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "score : 2.641686695798698  |  i \n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "score : 2.8160641795982198  |  do \n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "score : 3.0313199794950303  |  it \n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "score : 3.262345648333424  |  yes \n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "-----\n",
      "score : 2.856077080381165  |  do you \n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "score : 3.857663392329787  |  it was \n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "score : 4.356695295395741  |  i wonder \n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "score : 4.4037450017712825  |  it is \n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "score : 4.437963596908078  |  i agree \n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "-----\n",
      "score : 4.058384983842894  |  do you like \n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "score : 4.819249258894838  |  do you have \n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "score : 5.076054705148428  |  do you know \n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "score : 5.3216794838542185  |  i wonder if \n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "score : 5.529210195060541  |  do you use \n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "-----\n",
      "score : 5.3327577667653365  |  do you have a \n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "score : 6.378808781577483  |  do you have any \n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "score : 6.424154062565182  |  i wonder if they \n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "score : 6.436775036171841  |  do you like to \n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "score : 6.614728978778458  |  do you use facebook \n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "generate_beam_text(\"i wonder if they met how that would go from there\", 5, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "papermill": {
     "duration": 4.042042,
     "end_time": "2021-03-27T10:37:19.028001",
     "exception": false,
     "start_time": "2021-03-27T10:37:14.985959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "-----\n",
      "score : 0.6642091814824472  |  i \n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "score : 1.8629854359974094  |  yes \n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "score : 2.814706613507464  |  not \n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "score : 3.211038454162079  |  sometimes \n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "score : 3.4089753960044713  |  no \n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "-----\n",
      "score : 1.5047906370839623  |  i do \n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "score : 1.8489373037502599  |  i love \n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "score : 2.230968940370022  |  yes i \n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "score : 3.7556434167978  |  no i \n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "score : 3.783599214318431  |  i like \n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "-----\n",
      "score : 2.9423203334596524  |  i do like \n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "score : 3.1835362071395608  |  yes i love \n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "score : 3.329405278822552  |  i do do \n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "score : 3.338687598452328  |  yes i do \n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "score : 3.6817929156591944  |  i love to \n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "generate_beam_text(\"do you like comic books\", 4, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "papermill": {
     "duration": 4.859103,
     "end_time": "2021-03-27T10:37:26.095156",
     "exception": false,
     "start_time": "2021-03-27T10:37:21.236053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "-----\n",
      "score : 2.213055907412059  |  thanks \n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "score : 2.3703587775980983  |  have \n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "score : 2.409970616060191  |  bye \n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "score : 2.69881937030869  |  you \n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "score : 2.8767827535965185  |  same \n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "-----\n",
      "score : 2.4577104663522276  |  bye \n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "score : 2.5400805879612602  |  have a \n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "score : 2.8944776524617617  |  thanks \n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "score : 3.2401225042445403  |  you too \n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "score : 3.754665409991245  |  same here \n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "-----\n",
      "score : 2.9960385193798054  |  have a good \n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "score : 3.629835501230314  |  you too \n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "score : 3.887243339671484  |  have a great \n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "score : 4.259784269311603  |  same here \n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "score : 5.427137771691541  |  you too have \n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "-----\n",
      "score : 4.0319647015773645  |  have a good night \n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "score : 4.085919790596272  |  have a good day \n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "score : 4.396044614837783  |  have a great day \n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "score : 4.672711842032254  |  have a good one \n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "score : 5.397692591273667  |  have a great night \n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "generate_beam_text(\"thanks\", 5, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "papermill": {
     "duration": 4.499802,
     "end_time": "2021-03-27T10:37:32.782713",
     "exception": false,
     "start_time": "2021-03-27T10:37:28.282911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i do like to ',\n",
       " 'yes i do do ',\n",
       " 'yes i love to ',\n",
       " 'yes i do like ',\n",
       " 'i like ']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_beam_text(\"hi do you like to dance\", 5, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "def generate_beam_text(seed_text, next_words, beam_search_n, break_at_eos):\n",
    "    \n",
    "    distributions_scores_states = [[list(), 0.0, [None, None]]]\n",
    "    \n",
    "    decoder_states_value = None\n",
    "    \n",
    "    answers = []\n",
    "    \n",
    "    for _ in range(next_words):\n",
    "        \n",
    "        sequence_temp_candidates = list()\n",
    "        \n",
    "        for i in range(len(distributions_scores_states)): \n",
    "            \n",
    "            input_seq = np.zeros(\n",
    "                (1, max_encoder_seq_length), dtype=\"float32\"\n",
    "            )\n",
    "            \n",
    "            # Generate empty target sequence of length 1.\n",
    "            target_seq = np.zeros((1,1))\n",
    "            \n",
    "            seq, score, states_values = distributions_scores_states[i]\n",
    "            \n",
    "            if len(distributions_scores_states) == 1:\n",
    "                for t, word in enumerate(process(seed_text).split()):\n",
    "                    input_seq[0, t] = input_token_index[word]\n",
    "                \n",
    "                # Encode the input as state vectors.\n",
    "                decoder_states_value = encoder_model.predict(input_seq)\n",
    "                \n",
    "                # Populate the first character of target sequence with the start character.\n",
    "                target_seq[0, 0] = target_token_index['bos']\n",
    "                \n",
    "            else:\n",
    "                target_seq[0, 0] = seq[-1]\n",
    "                decoder_states_value = states_values\n",
    "                \n",
    "                candidate_sentence = \"\"\n",
    "                for token_index in seq:\n",
    "                    if token_index == eos_token:\n",
    "                        break\n",
    "                        \n",
    "                    word = reverse_target_char_index[token_index]\n",
    "                    candidate_sentence+=word + \" \"\n",
    "                \n",
    "                #print(\"score :\", score, \" | \", candidate_sentence)\n",
    "                answers.append((score, candidate_sentence))\n",
    "            \n",
    "            \n",
    "            output_tokens_distribution, h, c = decoder_model.predict([target_seq] + decoder_states_value)\n",
    "            \n",
    "            # Update states\n",
    "            decoder_states_value = [h, c]\n",
    "\n",
    "            predicted_distribution = output_tokens_distribution[0][0]\n",
    "            \n",
    "            for j in range(len(predicted_distribution)):\n",
    "                if predicted_distribution[j] > 0:\n",
    "                    candidate = [seq + [j], score - log(predicted_distribution[j]), decoder_states_value]\n",
    "                    if break_at_eos and j == eos_token:\n",
    "                        continue\n",
    "                    else:\n",
    "                        sequence_temp_candidates.append(candidate)\n",
    "\n",
    "        \n",
    "        # 2. score and sort all candidates\n",
    "        ordered = sorted(sequence_temp_candidates, key=lambda tup:tup[1])\n",
    "        \n",
    "        distributions_scores_states = ordered[:beam_search_n]\n",
    "          \n",
    "        #print(\"-----\")\n",
    "    \n",
    "    final_return_list = [x[1] for x in sorted(answers, reverse = True)[:5]]\n",
    "    return(final_return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 609.075203,
   "end_time": "2021-03-27T10:37:38.482862",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-27T10:27:29.407659",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
